[{"content":"Lets continue our journey with helpner-core, the spaCy project that does all the magic behind helpner.\nThis repository contains a spaCy template for a NER model, and allows to build the end-to-end spaCy workflow from the spacy project cli command manager. In short, spaCy projects present End-to-end NLP workflows from prototype to production.\nWe will visit the different steps of the whole workflow following the commands that involve the pipeline.\nhelpner-core workflow All this process is stored in the project.yml file, which contains the single source of truth for the project.\nDataset creation The first step is the dataset creation. I could have gone down the path of gathering a different number of CLI help messages and start labelling them, but it could easily get a very tedious task, and as the task allowed it, I started implementing a synthetic data generator (I will present cli-help-maker in a different post).\nLets introduce the first command:\nspacy project run create-dataset Running this command calls the program cli-help-maker, with a dataset.yaml file which contains the arguments needed for the program. This simplifies the versioning of the different data sets, we just have to store the yaml of any given version, all the relevant information to create a dataset is contained in a single file. Other than that the dataset contains random data with the layout and content we want the model to capture.\nThis command returns two files:\ndataset.jsonl: A jsonl file, where each line corresponds to a sample, that contains message and the annotations. {\u0026#34;message\u0026#34;:\u0026#34;Usage: \\n chedlock digynia borofluoric begirdle underbeadle [-d] [CONGRUENTLY...] [ACROBATISM... [ZONOID...]]\\n\\nFusillade preventively hogyard approachles.\\n\\nCommands:\\n digynia\\n...\u0026#34;, \u0026#34;annotations\u0026#34;: [[\u0026#34;CMD\u0026#34;,21,28],[\u0026#34;CMD\u0026#34;, 29,40]...] } {\u0026#34;message\u0026#34;: \u0026#34;usage: \\n sterelmintha hearth --hydromorphic-beethovian -g --titanical -e ODONTOLCATE-\\n...\u0026#34;, \u0026#34;annotations\u0026#34;:[[\u0026#34;CMD\u0026#34;,25,31],[\u0026#34;OPT\u0026#34;,32,57]...]} ... arguments.jsonl: Another jsonl file not used for during the program. We keep in this file the arguments that were used to generate each CLI help message, just for further analysis, to know what to expect from each dataset. {\u0026#34;indent_spaces\u0026#34;:4.0,\u0026#34;total_width\u0026#34;:120.0,...} {\u0026#34;indent_spaces\u0026#34;:4.0,\u0026#34;total_width\u0026#34;:78.0,...} Now we are ready to prepare the dataset for the training process.\nData workflow The process is divided in two different worflows just to outline the fact that the first part corresponds to data preparation, training and evaluation, while the next part deals with packaging related processes.\nData preparation This step involves two different scripts:\nsplit.py, which is run by the following program: spacy project run split This command simply splits the file in two different files dataset_train.jsonl and dataset_dev.jsonl with a random partition of 80/20. Given the dataset is generated randomly, there is no need for more complicated strategies.\nconvert.py, run by the following program: spacy project run convert It transforms the message in each row of the jsonl file to a serializable format: DocBin, to obtain two new files dataset_train.spacy and dataset_dev.spacy.\nIts time for some action!\nTraining The following program starts the training process:\nspacy project run train This command reads all the necessary info from the config files (you can read more in the spaCy training docs), which correspond to the NER components, CPU hardware and optimized for efficiency.\nIts created from the spaCy defaults, there is no need to change anything during this step. Given the model is just a proof of concept, and the dataset used is small enough, we can just train in our personal computer without a GPU, it just needs some minutes to finish the training process.\nAfter this step has finished, we are left with a directory containing our named entity recognition model.\nEvaluation After running the benchmark accuracy command we can inspect the model results on the development dataset. There should exist a different dataset to test the results, but for simplicity, the results are reported on this dataset, and the model is finally run against some help messages from real CLI apps (watch the helpner readme).\nspacy project run evaluate The output file of the command is a metrics.json file that contains information about the model\u0026rsquo;s performance (this content can be transferred to a README file easily as we will see later). The following table presents the information per entity, NER per type table:\nP R F CMD 98.25 99.96 99.10 ARG 94.79 89.97 92.32 OPT 98.88 98.96 98.92 The first thing to note is that the results seem to be really good for such a simple model with no special meaning besides the layout of the entities. The smallest value corresponds to the recall (R) value of ARG entities (89.97), the element that tends to get more confused, while the highest corresponds to the recall of CMD.\nBut, this results must be taken carefully, the dataset in which the model was trained is totaly synthetic, and the results may not be as good as expected in real data. It just shows that the model is able to learn from the data it was fed with.\nPackaging workflow Up to this point, we run the enabled workflows in project.yml file, which correspond to:\nspacy project run all Those are related to the data processing, model training and evaluation. A second workflow (more a subsequent set of commands) is for house keeping related tasks:\nPackaging The first of these commands is the package. SpaCy easily allows to generate a package automatically from our model, just by running a command, so it can be easily installed and loaded afterwards:\nspacy project run package Just place the contents generated somewhere accessible to pip, and you are ready to pip install the model to be used with spaCy. It even comes with a README.md file generated from the metrics.json file obtained, so the relevant content is autoexplained.\nFollowing the spaCy approach to model storage with spaCy models, the trained models are stored in the releases of the repository, and helpner deals with the installation process via pip install.\nReadme One last command and we are finished!\nSpaCy templates come with another magic command to generate a pretty README.md for your project: spacy project document. I wanted to add some more content automatically to this README file, and with a little script and the help of wasabi (a Explosion library which helps with console printing, but also with Markdown rendering), its as simple as it gets:\nspacy project run readme This command generates the readme for the helpner-core repository automatically, adding to the original generated README some additional metrics, like information from the dataset used for the current version, which seemed interesting enough to be added.\nDeployment The most relevant step make the model available for everybody easily isn\u0026rsquo;t properly mapped to a command, I have to do it manually for the moment üòÅ.\nBut lets assume the following command is already working (for the moment, this is done using GitHub in the browser directly):\nspacy project run release The previously created package is uploaded to github as a release (the releases can be seen in the following page), including a small description of the model\u0026rsquo;s accuracy, the weights and the necessary information to import the model just like any other spaCy model, after installation, it can be imported as usual in spaCy:\nimport spacy nlp = spacy.load(\u0026#34;en_helpner_core\u0026#34;) And just like we would do with any other spaCy model, we can pass text to it. As te expected input for the model are command line help messages, helpner helps dealing with the content directly on the shell.\nConclusion In this post we followed workflow outlined in helpner-core. We leveraged the power of spaCy project template to train, evaluate, and deploy a Named Entity Recognition model which can be pip installed as a dependency to run as any spaCy model. Feels amazing to deal with an end to end NLP pipeline with just a few command line programs.\n","permalink":"https://plaguss.github.io/blog/a-ner-model-for-command-line-help-messages-part2/","summary":"Lets continue our journey with helpner-core, the spaCy project that does all the magic behind helpner.\nThis repository contains a spaCy template for a NER model, and allows to build the end-to-end spaCy workflow from the spacy project cli command manager. In short, spaCy projects present End-to-end NLP workflows from prototype to production.\nWe will visit the different steps of the whole workflow following the commands that involve the pipeline.","title":"A NER Model for Command Line Help Messages (Part 2: spaCy projects to the rescue)"},{"content":"In this 3 part series I will tell the journey of creating a program to detect the different components/entities of a command line program\u0026rsquo;s help message. This post will start by looking at the final product helpner, a python program that can be installed from PyPI, the second will tell about the spaCy NLP workflow and finally we will take a look at the data that feeds spaCy\u0026rsquo;s final model.\nThe post assumes some python knowledge, like how to install a library from PyPI, and some familiarity with spaCy.\nThe following figure shows the architecture of helpner, each piece is represented by a different github repository. Highlighted in yellow at the bottom its the piece corresponding to helpner.\nWhat led me to start this project? I wanted an NLP project to put into practice the spaCy facilities. If possible, the model should be ready to use by an end user without developing a website for it for simplicity. Independently, I found docopt by chance exploring python CLI libraries. As it turns out, this library, and its maintained fork (docopt-ng) can generate a CLI program by parsing a \u0026ldquo;properly written\u0026rdquo; help message (visit the previous link to see an example). This same idea seemed like a good opportunity.\nCan we solve this using a Named Entity Recognition model? \u0026hellip;I don\u0026rsquo;t care if its not the best approach\nLets try to write a CLI program that can take a help message from another CLI program, and find the different elements or entities (commands, arguments and options) which conform it. It turns out that in around 200 lines of code, we can have a promising first version üòÑ. Of course, this is not that simple, but with spaCy it feels like it üëå.\nEnter helpner Lets see how helpner works. The installation consists of two steps. First, install using pip as usual preferably inside a venv. (It should be possible to install it using pipx, but I haven\u0026rsquo;t tried it yet):\n$ pip install helpner This should have downloaded the library, but as of this moment its incomplete, we still have to download the model itself. For this, a handy command is supplied (visit the README.md for more information):\n$ helpner download This two step process should be familiar for those who have already used spaCy. By using this approach it allows to split the development of the model from the use we make of it. We could update the model in any way (we could for example retrain the model with different data, or modify the optimizer used), and we would only need to update the model (running again the download command). It applies the same for the library, we could add more functionality without changing the inner model.\nWe are already in position to use helpner üí•, lets see one of the examples from the docs, how to highlight the entities of a help message (this was the first use that came to mind):\nflit install --help | helpner highlight For those who don\u0026rsquo;t know flit, its a command line program that simplifies packaging python modules. The example shows the help message of one of its subcommands, flit install. From the legend we see that the possible elements or entities are CMD (commands or subcommands, which in this case depend on flit directly), ARG (positional arguments, which in this case don\u0026rsquo;t exist) and OPT (optional arguments, which correspond to all the elements preceded by a single or double dash, are correctly predicted). But it calls the attention some random words highlighted as if they were CMD entities, which are clearly misplaced. It is far from perfect, but I consider it a success anyway, the results seem promising enough!\nWhat happens underneath? what we did was send the help message to the spaCy model, and get the predictions:\n‚ùØ flit install --help | helpner parse --no-json { \u0026#39;install\u0026#39;: (\u0026#39;CMD\u0026#39;, 12, 19), \u0026#39;[-h]\u0026#39;: (\u0026#39;OPT\u0026#39;, 20, 24), \u0026#39;[-s]\u0026#39;: (\u0026#39;OPT\u0026#39;, 25, 29), \u0026#39;[--pth-file]\u0026#39;: (\u0026#39;OPT\u0026#39;, 30, 42), \u0026#39;[--user]\u0026#39;: (\u0026#39;OPT\u0026#39;, 43, 51), \u0026#39;[--env]\u0026#39;: (\u0026#39;OPT\u0026#39;, 52, 59), \u0026#39;[--python PYTHON]\u0026#39;: (\u0026#39;OPT\u0026#39;, 60, 77), \u0026#39;[--deps {all,production,develop,none}]\u0026#39;: (\u0026#39;OPT\u0026#39;, 98, 136), \u0026#39;[--only-deps]\u0026#39;: (\u0026#39;OPT\u0026#39;, 137, 150), \u0026#39;[--extras EXTRAS]\u0026#39;: (\u0026#39;OPT\u0026#39;, 171, 188), \u0026#39;-h, --help\u0026#39;: (\u0026#39;OPT\u0026#39;, 201, 211), \u0026#39;exit\u0026#39;: (\u0026#39;CMD\u0026#39;, 250, 254), \u0026#39;-s, --symlink\u0026#39;: (\u0026#39;OPT\u0026#39;, 257, 270), \u0026#39;package\u0026#39;: (\u0026#39;CMD\u0026#39;, 298, 305), \u0026#39;--pth-file\u0026#39;: (\u0026#39;OPT\u0026#39;, 373, 383), \u0026#39;module\u0026#39;: (\u0026#39;CMD\u0026#39;, 417, 423), \u0026#39;/\u0026#39;: (\u0026#39;CMD\u0026#39;, 423, 424), \u0026#39;--user\u0026#39;: (\u0026#39;OPT\u0026#39;, 497, 503), \u0026#39;local\u0026#39;: (\u0026#39;CMD\u0026#39;, 529, 534), \u0026#39;--env\u0026#39;: (\u0026#39;OPT\u0026#39;, 612, 617), \u0026#39;--python PYTHON\u0026#39;: (\u0026#39;OPT\u0026#39;, 749, 764), \u0026#39;--deps {all,production,develop,none}\u0026#39;: (\u0026#39;OPT\u0026#39;, 862, 898), \u0026#39;--only-deps\u0026#39;: (\u0026#39;OPT\u0026#39;, 1074, 1085), \u0026#39;--extras EXTRAS\u0026#39;: (\u0026#39;OPT\u0026#39;, 1192, 1207), \u0026#39;the\u0026#39;: (\u0026#39;CMD\u0026#39;, 1313, 1316), \u0026#39;ones\u0026#39;: (\u0026#39;CMD\u0026#39;, 1317, 1321), \u0026#39;implied\u0026#39;: (\u0026#39;CMD\u0026#39;, 1322, 1329), \u0026#39;by\u0026#39;: (\u0026#39;CMD\u0026#39;, 1330, 1332), \u0026#39;be\u0026#39;: (\u0026#39;CMD\u0026#39;, 1382, 1384), \u0026#39;useful\u0026#39;: (\u0026#39;CMD\u0026#39;, 1385, 1391) } This output has all the necessary information to inform rich. The keys in the dict correspond to the elements found/predicted, and the values contain the entity, start and end position of the substrings. With this information, we can make use of rich to add some color to the console.\nOf course, there are multiple errors (and this is an example that seems relatively right), the model cannot be better than the data it was fed with. In a posterior post we will see how the data powering this model is obtained.\n","permalink":"https://plaguss.github.io/blog/a-ner-model-for-command-line-help-messages-part1/","summary":"In this 3 part series I will tell the journey of creating a program to detect the different components/entities of a command line program\u0026rsquo;s help message. This post will start by looking at the final product helpner, a python program that can be installed from PyPI, the second will tell about the spaCy NLP workflow and finally we will take a look at the data that feeds spaCy\u0026rsquo;s final model.","title":"A NER Model for Command Line Help Messages (Part 1: The command line program)"},{"content":"","permalink":"https://plaguss.github.io/archive/","summary":"archive","title":"Archive"}]